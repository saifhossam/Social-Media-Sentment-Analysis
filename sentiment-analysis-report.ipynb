{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-14T15:16:44.193222Z","iopub.execute_input":"2025-07-14T15:16:44.193833Z","iopub.status.idle":"2025-07-14T15:16:44.199021Z","shell.execute_reply.started":"2025-07-14T15:16:44.193809Z","shell.execute_reply":"2025-07-14T15:16:44.198399Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom datetime import datetime\nimport re\nimport nltk\nfrom nltk.tokenize import word_tokenize\n\n# تحميل الموارد اللازمة لـ NLTK\nnltk.download('punkt')\n\n# قائمة مخصصة من الكلمات الزائدة العربية\nARABIC_STOPWORDS = {\n    'من', 'في', 'على', 'إلى', 'عن', 'مع', 'بين', 'حتى', 'منذ', 'عند', 'فوق', 'تحت',\n    'أمام', 'خلف', 'هنا', 'هناك', 'كل', 'بعض', 'أي', 'هذا', 'هذه', 'تلك', 'ذلك',\n    'الذي', 'التي', 'اللذين', 'اللاتي', 'إن', 'أن', 'لكن', 'و', 'أو', 'لا', 'لم',\n    'لن', 'ما', 'ماذا', 'كيف', 'متى', 'أين', 'لماذا'\n}\n\n# تحميل نموذج تحليل المشاعر المحسن\nmodel_name = \"CAMeL-Lab/bert-base-arabic-camelbert-msa-sentiment\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\nsentiment_analyzer = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n\n# دالة لتنظيف النصوص\ndef clean_text(text):\n    # إزالة الرموز التعبيرية والرموز غير العربية\n    text = re.sub(r'[^\\u0621-\\u064A\\s0-9]', '', text)\n    # تحويل إلى حروف صغيرة\n    text = text.lower()\n    # إزالة الكلمات الزائدة\n    tokens = word_tokenize(text)\n    tokens = [word for word in tokens if word not in ARABIC_STOPWORDS]\n    return ' '.join(tokens)\n\n# دالة لتحليل المشاعر مع عتبة ثقة\ndef analyze_sentiments(comments, confidence_threshold=0.7):\n    results = []\n    for comment in comments:\n        cleaned_comment = clean_text(comment)\n        result = sentiment_analyzer(cleaned_comment)[0]\n        label = result['label']\n        score = result['score']\n        \n        # تحويل التسميات إلى إيجابي/سلبي/محايد\n        if label == 'positive' and score >= confidence_threshold:\n            sentiment = 'إيجابي'\n        elif label == 'negative' and score >= confidence_threshold:\n            sentiment = 'سلبي'\n        elif label == 'neutral' or score < confidence_threshold:\n            sentiment = 'محايد'\n        else:\n            sentiment = 'محايد'  # في حالة عدم اليقين\n        results.append({'تعليق': comment, 'تعليق_منظف': cleaned_comment, 'المشاعر': sentiment, 'الثقة': score})\n    return pd.DataFrame(results)\n\n# دالة لاستخراج الكلمات الشائعة\ndef get_common_words(df, sentiment, n=5):\n    words = []\n    for comment in df[df['المشاعر'] == sentiment]['تعليق_منظف']:\n        words.extend(word_tokenize(comment))\n    return Counter(words).most_common(n)\n\n# دالة لإنشاء تقرير تلقائي محسن\ndef generate_report(df, output_dir=\"reports\"):\n    os.makedirs(output_dir, exist_ok=True)\n    \n    # إحصائيات\n    sentiment_counts = Counter(df['المشاعر'])\n    total_comments = len(df)\n    positive_pct = (sentiment_counts['إيجابي'] / total_comments * 100) if 'إيجابي' in sentiment_counts else 0\n    negative_pct = (sentiment_counts['سلبي'] / total_comments * 100) if 'سلبي' in sentiment_counts else 0\n    neutral_pct = (sentiment_counts['محايد'] / total_comments * 100) if 'محايد' in sentiment_counts else 0\n    \n    # استخراج الكلمات الشائعة\n    positive_words = get_common_words(df, 'إيجابي')\n    negative_words = get_common_words(df, 'سلبي')\n    neutral_words = get_common_words(df, 'محايد')\n    \n    # إنشاء التقرير\n    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n    report_content = f\"\"\"\n# تقرير تحليل المشاعر المحسن\n## تاريخ التقرير: {timestamp}\n\n### ملخص الإحصائيات\n- **إجمالي التعليقات**: {total_comments}\n- **إيجابية**: {sentiment_counts.get('إيجابي', 0)} ({positive_pct:.2f}%)\n- **سلبية**: {sentiment_counts.get('سلبي', 0)} ({negative_pct:.2f}%)\n- **محايدة**: {sentiment_counts.get('محايد', 0)} ({neutral_pct:.2f}%)\n\n### التعليقات التفصيلية\n| التعليق | المشاعر | الثقة |\n|----------|----------|--------|\n\"\"\"\n    for _, row in df.iterrows():\n        report_content += f\"| {row['تعليق']} | {row['المشاعر']} | {row['الثقة']:.2f} |\\n\"\n\n    # حفظ التقرير\n    report_path = f\"{output_dir}/sentiment_report_{timestamp}.md\"\n    with open(report_path, 'w', encoding='utf-8') as f:\n        f.write(report_content)\n    \n    # إنشاء رسم بياني\n    plt.figure(figsize=(8, 6))\n    sns.barplot(x=list(sentiment_counts.keys()), y=list(sentiment_counts.values()))\n    plt.title(\"توزيع المشاعر في التعليقات\")\n    plt.xlabel(\"المشاعر\")\n    plt.ylabel(\"عدد التعليقات\")\n    plt_path = f\"{output_dir}/sentiment_plot_{timestamp}.png\"\n    plt.savefig(plt_path)\n    plt.close()\n    \n    return report_path, plt_path\n\n# مثال للتعليقات\nif __name__ == \"__main__\":\n    comments = [\n        \"المنتج رائع وسهل الاستخدام! 😊\",\n        \"خدمة العملاء سيئة جدًا وغير متعاونة 😡\",\n        \"المنتج عادي، لا بأس به 😐\",\n        \"تجربة ممتازة، سأشتري مرة أخرى 👍\",\n        \"التوصيل تأخر كثيرًا 😞\"\n    ]\n    \n    # تحليل المشاعر\n    df = analyze_sentiments(comments)\n    \n    # إنشاء التقرير\n    report_path, plot_path = generate_report(df)\n    print(f\"تم إنشاء التقرير في: {report_path}\")\n    print(f\"تم إنشاء الرسم البياني في: {plot_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T16:14:49.800521Z","iopub.execute_input":"2025-07-14T16:14:49.801097Z","iopub.status.idle":"2025-07-14T16:14:51.314303Z","shell.execute_reply.started":"2025-07-14T16:14:49.801074Z","shell.execute_reply":"2025-07-14T16:14:51.313497Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\nDevice set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"تم إنشاء التقرير في: reports/sentiment_report_2025-07-14_16-14-51.md\nتم إنشاء الرسم البياني في: reports/sentiment_plot_2025-07-14_16-14-51.png\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/seaborn/_oldcore.py:1765: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n  order = pd.unique(vector)\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"import shutil\n\nshutil.rmtree('/kaggle/working/reports')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T16:13:36.645280Z","iopub.execute_input":"2025-07-14T16:13:36.646188Z","iopub.status.idle":"2025-07-14T16:13:36.650863Z","shell.execute_reply.started":"2025-07-14T16:13:36.646164Z","shell.execute_reply":"2025-07-14T16:13:36.650181Z"}},"outputs":[],"execution_count":76}]}